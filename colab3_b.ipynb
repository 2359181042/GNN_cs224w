{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9DbuerWkLS2CHgEhAOMUr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2359181042/GNN_cs224w/blob/main/colab3_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF-6hCSZThXA",
        "outputId": "9c05833d-4eca-4152-c90d-75bc08488af6"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.6MB 3.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 4.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 8.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQtGKGfRTlb7",
        "outputId": "e7c6abc7-50bb-40ae-afd7-6f722da87ea9"
      },
      "source": [
        "!pip install deepsnap"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepsnap in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepsnap) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from deepsnap) (1.9.0+cu102)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from deepsnap) (2.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->deepsnap) (3.7.4.3)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->deepsnap) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFt2VkXPTnGF"
      },
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGOM4vCoUQDk",
        "outputId": "08c28baf-847f-4a13-bc85-0dcd3fb7258b"
      },
      "source": [
        "root = './tmp/cora'\n",
        "name = 'Cora'\n",
        "\n",
        "# The Cora dataset\n",
        "pyg_dataset= Planetoid(root, name)\n",
        "\n",
        "# PyG dataset to a list of deepsnap graphs\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Get the first deepsnap graph (CORA only has one graph)\n",
        "graph = graphs[0]\n",
        "print(graph)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Graph(G=[], edge_index=[2, 10556], edge_label_index=[2, 10556], node_feature=[2708, 1433], node_label=[2708], node_label_index=[2708])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXkl0zxKUkL_"
      },
      "source": [
        "## Question 2.1: What is the number of classes and number of features in the CORA graph? (5 points)\n",
        "\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyqf1fB1UUSS",
        "outputId": "0501fe5c-9f29-421c-d4a6-0ffc910e0d2a"
      },
      "source": [
        "def get_num_node_classes(graph):\n",
        "  # TODO: Implement this function that takes a deepsnap graph object\n",
        "  # and return the number of node classes of that graph.\n",
        "\n",
        "  num_node_classes = 0\n",
        "\n",
        "  ############# Your code here #############\n",
        "  ## (~1 line of code)\n",
        "  ## Note\n",
        "  ## 1. Colab autocomplete functionality might be useful\n",
        "  ## 2. DeepSNAP documentation might be useful https://snap.stanford.edu/deepsnap/modules/graph.html\n",
        "  pass\n",
        "\n",
        "  ##########################################\n",
        "\n",
        "  return num_node_classes\n",
        "\n",
        "def get_num_node_features(graph):\n",
        "  # TODO: Implement this function that takes a deepsnap graph object\n",
        "  # and return the number of node features of that graph.\n",
        "\n",
        "  num_node_features = graph.num_node_features\n",
        "  ############# Your code here #############\n",
        "  ## (~1 line of code)\n",
        "  ## Note\n",
        "  ## 1. Colab autocomplete functionality might be useful\n",
        "  ## 2. DeepSNAP documentation might be useful https://snap.stanford.edu/deepsnap/modules/graph.html\n",
        "\n",
        "\n",
        "  ##########################################\n",
        "\n",
        "  return num_node_features\n",
        "\n",
        "num_node_classes = get_num_node_classes(graph)\n",
        "num_node_features = get_num_node_features(graph)\n",
        "print(\"{} has {} classes\".format(name, num_node_classes))\n",
        "print(\"{} has {} features\".format(name, num_node_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cora has 0 classes\n",
            "Cora has 1433 features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ywtm8_eWHoZ"
      },
      "source": [
        "## DeepSNAP Dataset\n",
        "\n",
        "Now, lets talk about DeepSNAP dataset. A `deepsnap.dataset.GraphDataset` contains a list of `deepsnap.graph.Graph` objects. In addition to list of graphs, you can also specify what task the dataset will be used on, such as node level task (`task=node`), edge level task (`task=link_pred`) and graph level task (`task=graph`).\n",
        "\n",
        "It also contains many other useful parameters during initialization and other functinoalities. If you are interested, you can take a look at the [documentation](https://snap.stanford.edu/deepsnap/modules/dataset.html#deepsnap-graphdataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7c2QdmVgGMw"
      },
      "source": [
        "Lets now use COX2 dataset which contains a list of graphs and specify the task to graph when we initialize the DeepSNAP dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P07sZk6dgIFq",
        "outputId": "4918dbb7-a8fb-4ce3-fba6-a8261547c2b2"
      },
      "source": [
        "root = './tmp/cox2'\n",
        "name = 'COX2'\n",
        "\n",
        "# Load the dataset through PyG\n",
        "pyg_dataset = TUDataset(root, name)\n",
        "\n",
        "# Convert to a list of deepsnap graphs\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Convert list of deepsnap graphs to deepsnap dataset with specified task=graph\n",
        "dataset = GraphDataset(graphs, task='graph')\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/COX2.zip\n",
            "Extracting tmp/cox2/COX2/COX2.zip\n",
            "Processing...\n",
            "Done!\n",
            "GraphDataset(467)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lMURMNRgXE1"
      },
      "source": [
        "Question 2.2: What is the label of the graph (index 100 in the COX2 dataset)? (5 points)\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQzVvfAhgThw",
        "outputId": "11d76c08-889d-4e00-e63e-73e5b9df5e85"
      },
      "source": [
        "def get_graph_class(dataset, idx):\n",
        "  # TODO: Implement this function that takes a deepsnap dataset object,\n",
        "  # the index of the graph in the dataset, and returns the class/label \n",
        "  # of the graph (in integer).\n",
        "\n",
        "  label = -1\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~1 line of code)\n",
        "  ## Note\n",
        "  ## 1. The label refers to the graph-level attribute\n",
        "  label = dataset[idx]\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return label\n",
        "\n",
        "graph_0 = dataset[0]\n",
        "print(graph_0)\n",
        "idx = 100\n",
        "label = get_graph_class(dataset, idx)\n",
        "print('Graph with index {} has label {}'.format(idx, label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph(G=[], edge_index=[2, 82], edge_label_index=[2, 82], graph_label=[1], node_feature=[39, 35], node_label_index=[39], task=[])\n",
            "Graph with index 100 has label Graph(G=[], edge_index=[2, 78], edge_label_index=[2, 78], graph_label=[1], node_feature=[37, 35], node_label_index=[37], task=[])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKEtieAphJuq"
      },
      "source": [
        "Question 2.3: What is the number of edges for the graph (index 200 in the COX2 dataset)? (5 points)\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50hzKZcnhHDQ",
        "outputId": "58adc36c-fbe9-4922-8051-74b8456bc773"
      },
      "source": [
        "def get_graph_num_edges(dataset, idx):\n",
        "  # TODO: Implement this function that takes a deepsnap dataset object,\n",
        "  # the index of the graph in dataset, and returns the number of \n",
        "  # edges in the graph (in integer).\n",
        "\n",
        "  num_edges = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~1 lines of code)\n",
        "  ## Note\n",
        "  ## 1. You can use the class property directly\n",
        "  num_edges=dataset[idx].num_edges\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return num_edges\n",
        "\n",
        "idx = 200\n",
        "num_edges = get_graph_num_edges(dataset, idx)\n",
        "print('Graph with index {} has {} edges'.format(idx, num_edges))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph with index 200 has 49 edges\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1anSsca6haz-"
      },
      "source": [
        "# 3 DeepSNAP Advanced\n",
        "\n",
        "We have learned the basic use of DeepSNAP graph and dataset :)\n",
        "\n",
        "Lets move on to some more advanced functionalities.\n",
        "\n",
        "In this section we will use DeepSNAP for faeture computation and transductive/inductive splittings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M71RTKahgx-"
      },
      "source": [
        "##setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJhPiAt6hd4z"
      },
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9BXdIqBhrLY"
      },
      "source": [
        "## Data Split in Graphs\n",
        "\n",
        "Data splitting in graphs can be much harder than that in CV or NLP.\n",
        "\n",
        "In general, the data splitting in graphs can be divided into two settings, **inductive** and **transductive**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVCmivhVhsH_"
      },
      "source": [
        "## Inductive Split\n",
        "\n",
        "As what we have learned in the lecture, inductive setting will split multiple graphs into each training/valiation and test sets.\n",
        "\n",
        "Here is an example of DeepSNAP inductive splitting for a list of graphs in the graph level task (graph classification etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuSiUVm8Tq7L",
        "outputId": "8732751c-071a-4626-c8dc-51205c94e596"
      },
      "source": [
        "root = './tmp/cox2'\n",
        "name = 'COX2'\n",
        "\n",
        "pyg_dataset = TUDataset(root, name)\n",
        "\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Here we specify the task as graph-level task such as graph classification\n",
        "task = 'graph'\n",
        "dataset = GraphDataset(graphs, task=task)\n",
        "\n",
        "# Specify transductive=False (inductive)\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=False, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "print(\"COX2 train dataset: {}\".format(dataset_train))\n",
        "print(\"COX2 validation dataset: {}\".format(dataset_val))\n",
        "print(\"COX2 test dataset: {}\".format(dataset_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COX2 train dataset: GraphDataset(373)\n",
            "COX2 validation dataset: GraphDataset(46)\n",
            "COX2 test dataset: GraphDataset(48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD4I36FrigQY"
      },
      "source": [
        "## Transductive Split\n",
        "\n",
        "In transductive setting, the training /validation / test sets are on the same graph.\n",
        "\n",
        "Here we transductively split the CORA graph in the node level task. \n",
        "\n",
        "(Notice that in DeepSNAP default setting the split is random, but you can also make a fixed split by specifying `fixed_split=True` when loading the dataset from PyG or changing the `node_label_index` directly)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaLckdZgic6N",
        "outputId": "3c340e14-247e-466a-f8c6-ca1ffa80d8ef"
      },
      "source": [
        "root = './tmp/cora'\n",
        "name = 'Cora'\n",
        "\n",
        "pyg_dataset = Planetoid(root, name)\n",
        "\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Here we specify the task as node-level task such as node classification\n",
        "task = 'node'\n",
        "\n",
        "dataset = GraphDataset(graphs, task=task)\n",
        "\n",
        "# Specify we want the transductive splitting\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "print(\"Cora train dataset: {}\".format(dataset_train))\n",
        "print(\"Cora validation dataset: {}\".format(dataset_val))\n",
        "print(\"Cora test dataset: {}\".format(dataset_test))\n",
        "\n",
        "print(\"Original Cora has {} nodes\".format(dataset.num_nodes[0]))\n",
        "\n",
        "# The nodes in each set can be find in node_label_index\n",
        "print(\"After the split, Cora has {} training nodes\".format(dataset_train[0].node_label_index.shape[0]))\n",
        "print(\"After the split, Cora has {} validation nodes\".format(dataset_val[0].node_label_index.shape[0]))\n",
        "print(\"After the split, Cora has {} test nodes\".format(dataset_test[0].node_label_index.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cora train dataset: GraphDataset(1)\n",
            "Cora validation dataset: GraphDataset(1)\n",
            "Cora test dataset: GraphDataset(1)\n",
            "Original Cora has 2708 nodes\n",
            "After the split, Cora has 2166 training nodes\n",
            "After the split, Cora has 270 validation nodes\n",
            "After the split, Cora has 272 test nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDKuVxV0jDZv"
      },
      "source": [
        "## Edge Level Split\n",
        "\n",
        "Compared to the node and graph level splitting, edge level splitting is a little bit tricky ;)\n",
        "\n",
        "Usually in edge level splitting, we need to sample negative edges, split positive edges into different datasets, split training edges into message passing edges and supervision edges, and resample the negative edges during the training etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNlpz3UTjJjb"
      },
      "source": [
        "### All Mode\n",
        "\n",
        "Now lets start with a simpler edge level splitting mode, the `edge_train_mode=\"all\"` mode in DeepSNAP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81kiNIm4jA6Z",
        "outputId": "f7902e6a-6116-4562-d768-bb842f9f9a7f"
      },
      "source": [
        "root = './tmp/cora'\n",
        "name = 'Cora'\n",
        "\n",
        "pyg_dataset = Planetoid(root, name)\n",
        "\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Specify task as link_pred for edge-level task\n",
        "task = 'link_pred'\n",
        "\n",
        "# Specify the train mode, \"all\" mode is default for deepsnap dataset\n",
        "edge_train_mode = \"all\"\n",
        "\n",
        "dataset = GraphDataset(graphs, task=task, edge_train_mode=edge_train_mode)\n",
        "\n",
        "# Transductive link prediction split\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "print(\"Cora train dataset: {}\".format(dataset_train))\n",
        "print(\"Cora validation dataset: {}\".format(dataset_val))\n",
        "print(\"Cora test dataset: {}\".format(dataset_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Cora train dataset: GraphDataset(1)\n",
            "Cora validation dataset: GraphDataset(1)\n",
            "Cora test dataset: GraphDataset(1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvV8ZmP7jkXL"
      },
      "source": [
        "In DeepSNAP, the indices of supervision edges are stored in `edge_label_index` tensor and the corresponding edge labels are stored in `edge_label` tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cw18hWvjnGG",
        "outputId": "3e1fc131-7ce0-4386-fa6c-57bdc9456c44"
      },
      "source": [
        "print(\"Original Cora graph has {} edges\".format(dataset[0].num_edges))\n",
        "print(\"Because Cora graph is undirected, the original edge_index has shape {}\".format(dataset[0].edge_index.shape))\n",
        "\n",
        "print(\"The training set has message passing edge index shape {}\".format(dataset_train[0].edge_index.shape))\n",
        "print(\"The training set has supervision edge index shape {}\".format(dataset_train[0].edge_label_index.shape))\n",
        "\n",
        "print(\"The validation set has message passing edge index shape {}\".format(dataset_val[0].edge_index.shape))\n",
        "print(\"The validation set has supervision edge index shape {}\".format(dataset_val[0].edge_label_index.shape))\n",
        "\n",
        "print(\"The test set has message passing edge index shape {}\".format(dataset_test[0].edge_index.shape))\n",
        "print(\"The test set has supervision edge index shape {}\".format(dataset_test[0].edge_label_index.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Cora graph has 5278 edges\n",
            "Because Cora graph is undirected, the original edge_index has shape torch.Size([2, 10556])\n",
            "The training set has message passing edge index shape torch.Size([2, 8444])\n",
            "The training set has supervision edge index shape torch.Size([2, 16888])\n",
            "The validation set has message passing edge index shape torch.Size([2, 8444])\n",
            "The validation set has supervision edge index shape torch.Size([2, 2108])\n",
            "The test set has message passing edge index shape torch.Size([2, 9498])\n",
            "The test set has supervision edge index shape torch.Size([2, 2116])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcd31y-9kx3y"
      },
      "source": [
        "We can see that both training and validation sets have the same message passing edges (`edge_index`) in the `all` mode. Also, in training set, the postive supervision edges (`edge_label_index`) are same with the message passing edges. However, in the test set the message passing edges are the combination of message passing edges from training and validation sets.\n",
        "\n",
        "Notice that the `edge_label` and `edge_label_index` have included the negative edges (default number of negative edges is same with the number of positive edges).\n",
        "\n",
        "Now, lets implement a function that checks whether two edge index tensors are disjoint and explore more edge splitting properties by using that function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StXMySpFlzk9"
      },
      "source": [
        "## Question 3.1 - 3.5: Implement the function that checks whether two edge_index tensors are disjoint. Then answer the True/False questions below. (5 points)\n",
        "\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ISdjjSMl5w7"
      },
      "source": [
        "def edge_indices_disjoint(edge_index_1, edge_index_2):\n",
        "  # TODO: Implement this function that takes two edge index tensors,\n",
        "  # and returns whether these two edge index tensors are disjoint.\n",
        "  disjoint = None\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~5 lines of code)\n",
        "  ## Note\n",
        "  ## 1. Here disjoint means that there is no single edge belongs to either edge index tensors\n",
        "  ## 2. You do not need to consider the undirected case. For example, if edge_index_1 contains\n",
        "  ## edge (a, b) and edge_index_2 contains edge (b, a). We will treat them as disjoint in this\n",
        "  ## function.\n",
        "  #试过用遍历，特别慢，所以用集合\n",
        "  \n",
        "  #代码逻辑是将一个数据集的tuple形式的边储存进集合中\n",
        "  #然后将第二个数据集的边逐一验证是否在集合中\n",
        "  edge_set=set()\n",
        "  for i in range(edge_index_1.shape[1]):\n",
        "    e=tuple(edge_index_1[:,i].numpy())\n",
        "    edge_set.add(e)\n",
        "  for j in range(edge_index_2.shape[1]):\n",
        "    e=tuple(edge_index_2[:,j].numpy())\n",
        "    if e in edge_set:\n",
        "      return False\n",
        "  disjoint=True\n",
        "  return disjoint\n",
        "\n",
        "\n",
        "  return disjoint"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWh1RJSHtxH3",
        "outputId": "aa9cd844-2f6b-4b0c-9a76-fba936426c7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "edge_index_1=torch.tensor([[1,1,2,3,4],[2,3,1,1,3]])\n",
        "edge_index_2=torch.tensor([[1,1,2,3,4],[3,4,1,4,3]])\n",
        "edge_indices_disjoint(edge_index_1, edge_index_2)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ils4xXmtuO3A",
        "outputId": "f3d449e1-75ec-4082-892f-d6b1a93d94c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "edge_set=set()\n",
        "for i in range(edge_index_1.shape[1]):\n",
        "  print(i)\n",
        "  e=tuple(edge_index_1[:,i].numpy())\n",
        "  print(e)\n",
        "  edge_set.add(e)\n",
        "print(edge_set)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(1, 2)\n",
            "1\n",
            "(1, 3)\n",
            "2\n",
            "(2, 1)\n",
            "3\n",
            "(3, 1)\n",
            "4\n",
            "(4, 3)\n",
            "{(1, 2), (1, 3), (3, 1), (2, 1), (4, 3)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_JoTJhKCOHc",
        "outputId": "71604b8a-7123-4f64-a161-0d19972cf66b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_train_edges = dataset_train[0].edge_label_index.shape[1] // 2\n",
        "train_pos_edge_index = dataset_train[0].edge_label_index[:, :num_train_edges]\n",
        "train_neg_edge_index = dataset_train[0].edge_label_index[:, num_train_edges:]\n",
        "print(\"3.1 Training (supervision) positve and negative edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(train_pos_edge_index, train_neg_edge_index)))\n",
        "\n",
        "num_val_edges = dataset_val[0].edge_label_index.shape[1] // 2\n",
        "val_pos_edge_index = dataset_val[0].edge_label_index[:, :num_val_edges]\n",
        "val_neg_edge_index = dataset_val[0].edge_label_index[:, num_val_edges:]\n",
        "print(\"3.2 Validation (supervision) positve and negative edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(val_pos_edge_index, val_neg_edge_index)))\n",
        "\n",
        "num_test_edges = dataset_test[0].edge_label_index.shape[1] // 2\n",
        "test_pos_edge_index = dataset_test[0].edge_label_index[:, :num_test_edges]\n",
        "test_neg_edge_index = dataset_test[0].edge_label_index[:, num_test_edges:]\n",
        "print(\"3.3 Test (supervision) positve and negative edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(test_pos_edge_index, test_neg_edge_index)))\n",
        "\n",
        "print(\"3.4 Test (supervision) positve and validation (supervision) positve edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(test_pos_edge_index, val_pos_edge_index)))\n",
        "print(\"3.5 Validation (supervision) positve and training (supervision) positve edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(val_pos_edge_index, train_pos_edge_index)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.1 Training (supervision) positve and negative edges are disjoint = True\n",
            "3.2 Validation (supervision) positve and negative edges are disjoint = True\n",
            "3.3 Test (supervision) positve and negative edges are disjoint = True\n",
            "3.4 Test (supervision) positve and validation (supervision) positve edges are disjoint = True\n",
            "3.5 Validation (supervision) positve and training (supervision) positve edges are disjoint = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xf2mo0bDARb"
      },
      "source": [
        "### Disjoint Mode\n",
        "\n",
        "Now lets look at a relatively more complex transductive edge split setting, which is the `edge_train_mode=\"disjoint\"` mode in DeepSNAP (also the transductive link prediction splitting talked in the lecture)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqq3xlu3DPgp",
        "outputId": "1d55fb27-1610-4ba2-faef-d6bc896d2740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "edge_train_mode = \"disjoint\"\n",
        "\n",
        "dataset = GraphDataset(graphs, task='link_pred', edge_train_mode=edge_train_mode)\n",
        "orig_edge_index = dataset[0].edge_index\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(\n",
        "    transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "train_message_edge_index = dataset_train[0].edge_index\n",
        "train_sup_edge_index = dataset_train[0].edge_label_index\n",
        "val_sup_edge_index = dataset_val[0].edge_label_index\n",
        "test_sup_edge_index = dataset_test[0].edge_label_index\n",
        "\n",
        "print(\"The edge index of original graph has shape: {}\".format(orig_edge_index.shape))\n",
        "print(\"The edge index of training message edges has shape: {}\".format(train_message_edge_index.shape))\n",
        "print(\"The edge index of training supervision edges has shape: {}\".format(train_sup_edge_index.shape))\n",
        "print(\"The edge index of validation message edges has shape: {}\".format(dataset_val[0].edge_index.shape))\n",
        "print(\"The edge index of validation supervision edges has shape: {}\".format(val_sup_edge_index.shape))\n",
        "print(\"The edge index of test message edges has shape: {}\".format(dataset_test[0].edge_index.shape))\n",
        "print(\"The edge index of test supervision edges has shape: {}\".format(test_sup_edge_index.shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The edge index of original graph has shape: torch.Size([2, 10556])\n",
            "The edge index of training message edges has shape: torch.Size([2, 6754])\n",
            "The edge index of training supervision edges has shape: torch.Size([2, 3380])\n",
            "The edge index of validation message edges has shape: torch.Size([2, 8444])\n",
            "The edge index of validation supervision edges has shape: torch.Size([2, 2108])\n",
            "The edge index of test message edges has shape: torch.Size([2, 9498])\n",
            "The edge index of test supervision edges has shape: torch.Size([2, 2116])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivLjBZ5lDulk"
      },
      "source": [
        "You can see that the training / validation message passing edges and training supervision edges are splitted differently in those two modes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrhsdWS_Dv_a"
      },
      "source": [
        "### Resample Negative Edges\n",
        "\n",
        "During each training iteration, we usually need to resample the negative edges.\n",
        "\n",
        "Below we print the training and validation sets negative edges in two training iterations.\n",
        "\n",
        "You should find that the negative edges in training set will be resampled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugW1WpuRD1pg",
        "outputId": "54872870-6c8c-491c-c61f-0ec98bfbe5a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = GraphDataset(graphs, task='link_pred', edge_train_mode=\"disjoint\")\n",
        "datasets = {}\n",
        "follow_batch = []\n",
        "datasets['train'], datasets['val'], datasets['test'] = dataset.split(\n",
        "    transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "dataloaders = {\n",
        "  split: DataLoader(\n",
        "    ds, collate_fn=Batch.collate(follow_batch),\n",
        "    batch_size=1, shuffle=(split=='train')\n",
        "  )\n",
        "  for split, ds in datasets.items()\n",
        "}\n",
        "neg_edges_1 = None\n",
        "for batch in dataloaders['train']:\n",
        "  num_edges = batch.edge_label_index.shape[1] // 2\n",
        "  neg_edges_1 = batch.edge_label_index[:, num_edges:]\n",
        "  print(\"First iteration training negative edges:\")\n",
        "  print(neg_edges_1)\n",
        "  break\n",
        "neg_edges_2 = None\n",
        "for batch in dataloaders['train']:\n",
        "  num_edges = batch.edge_label_index.shape[1] // 2\n",
        "  neg_edges_2 = batch.edge_label_index[:, num_edges:]\n",
        "  print(\"Second iteration training negative edges:\")\n",
        "  print(neg_edges_2)\n",
        "  break\n",
        "\n",
        "neg_edges_1 = None\n",
        "for batch in dataloaders['val']:\n",
        "  num_edges = batch.edge_label_index.shape[1] // 2\n",
        "  neg_edges_1 = batch.edge_label_index[:, num_edges:]\n",
        "  print(\"First iteration validation negative edges:\")\n",
        "  print(neg_edges_1)\n",
        "  break\n",
        "neg_edges_2 = None\n",
        "for batch in dataloaders['val']:\n",
        "  num_edges = batch.edge_label_index.shape[1] // 2\n",
        "  neg_edges_2 = batch.edge_label_index[:, num_edges:]\n",
        "  print(\"Second iteration validation negative edges:\")\n",
        "  print(neg_edges_2)\n",
        "  break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First iteration training negative edges:\n",
            "tensor([[2268, 2315,  404,  ..., 1413,  370, 2284],\n",
            "        [ 212, 1999,  753,  ...,   11,  988, 1513]])\n",
            "Second iteration training negative edges:\n",
            "tensor([[1802, 1629, 1868,  ...,  821,  239,  392],\n",
            "        [ 575,  473,  809,  ..., 1336,  589, 1795]])\n",
            "First iteration validation negative edges:\n",
            "tensor([[2293,  750,  880,  ..., 1915, 1342,  236],\n",
            "        [ 154, 1589, 1526,  ..., 1430,  839,   28]])\n",
            "Second iteration validation negative edges:\n",
            "tensor([[2293,  750,  880,  ..., 1915, 1342,  236],\n",
            "        [ 154, 1589, 1526,  ..., 1430,  839,   28]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30cp8R47Mjfk"
      },
      "source": [
        "If you are interested in more graph splitting settings, please refer to the DeepSNAP dataset [documentation](https://snap.stanford.edu/deepsnap/modules/dataset.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8t00H5SMkl1"
      },
      "source": [
        "## Graph Transformation and Feature Computation\n",
        "\n",
        "The other DeepSNAP core functionality is graph transformation / feature computation.\n",
        "\n",
        "In DeepSNAP, we divide graph transformation / feature computation into two different types. One is the transformation before training (transform the whole dataset before training directly) and another one is the transformation during training (transform batches of graphs).\n",
        "\n",
        "Here is an example that uses NetworkX back end to calculate the PageRank value and update the value to tensors before the training (transform the dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eSgu4XfM2kd",
        "outputId": "b48eb678-a929-46c6-a1db-18676f88dc1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def pagerank_transform_fn(graph):\n",
        "\n",
        "  # Get the referenced networkx graph\n",
        "  G = graph.G\n",
        "\n",
        "  # Calculate the pagerank by using networkx\n",
        "  pr = nx.pagerank(G)\n",
        "\n",
        "  # Transform the pagerank values to tensor\n",
        "  pr_feature = torch.tensor([pr[node] for node in range(graph.num_nodes)], dtype=torch.float32)\n",
        "  pr_feature = pr_feature.view(graph.num_nodes, 1)\n",
        "\n",
        "  # Concat the pagerank values to the node feature\n",
        "  graph.node_feature = torch.cat([graph.node_feature, pr_feature], dim=-1)\n",
        "\n",
        "root = './tmp/cox2'\n",
        "name = 'COX2'\n",
        "pyg_dataset = TUDataset(root, name)\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "dataset = GraphDataset(graphs, task='graph')\n",
        "print(\"Number of features before transformation: {}\".format(dataset.num_node_features))\n",
        "dataset.apply_transform(pagerank_transform_fn, update_tensor=False)\n",
        "print(\"Number of features after transformation: {}\".format(dataset.num_node_features))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/COX2.zip\n",
            "Extracting tmp/cox2/COX2/COX2.zip\n",
            "Processing...\n",
            "Done!\n",
            "Number of features before transformation: 35\n",
            "Number of features after transformation: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8SCdnV9N7SX"
      },
      "source": [
        "Apart from transforming the dataset, DeepSNAP can also transform the graph (usually the `deepsnap.batch.Batch`) during each training iteration.\n",
        "\n",
        "Also, DeepSNAP supports the synchronization of the transformation between the referenced graph objects and tensor representations. For example, you can just update the NetworkX graph object in the transform function, and by specifying `update_tensor=True` the internal tensor representations will be automatically updated.\n",
        "\n",
        "For more information, please refer to the DeepSNAP [documentation](https://snap.stanford.edu/deepsnap/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxx0MNJ4OET4"
      },
      "source": [
        "# 4 Edge Level Prediction\n",
        "\n",
        "From last section, we know how DeepSNAP transductive split the edges in the link prediction task.\n",
        "\n",
        "Now lets use DeepSNAP and PyG together to implement a edge level prediction (link prediction) model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmiwK5YtN8V5"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "class LinkPredModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.2):\n",
        "        super(LinkPredModel, self).__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, num_classes)\n",
        "\n",
        "        self.loss_fn = None\n",
        "\n",
        "        ############# Your code here #############\n",
        "        ## (~1 line of code)\n",
        "        ## Note\n",
        "        ## 1. Initialize the loss function to BCEWithLogitsLoss\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        ##########################################\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "    def forward(self, batch):\n",
        "        node_feature, edge_index, edge_label_index = batch.node_feature, batch.edge_index, batch.edge_label_index\n",
        "        \n",
        "        ############# Your code here #############\n",
        "        ## (~6 line of code)\n",
        "        ## Note\n",
        "        ## 1. Feed the node feature into the first conv layer\n",
        "        ## 2. Add a ReLU after the first conv layer\n",
        "        ## 3. Add dropout after the ReLU (with probability self.dropout)\n",
        "        ## 4. Feed the output to the second conv layer\n",
        "        ## 5. Select the embeddings of the source nodes and destination nodes\n",
        "        ## by using the edge_label_index and compute the similarity of each pair\n",
        "        ## by dot product\n",
        "        pred = self.conv1(node_feature,edge_index)\n",
        "        pred = F.relu(pred)\n",
        "        pred = F.dropout(pred, self.dropout,self.training)\n",
        "        pred=self.conv2(pred,edge_index)\n",
        "        sp_edges=pred[edge_label_index] #[2,supervision边数,num_classes]\n",
        "        source_nodes=sp_edges[0]  #[supervision边数,num_classes]\n",
        "        destination_nodes=sp_edges[1]\n",
        "        pred=(source_nodes*destination_nodes).sum(axis=1)\n",
        "        ##########################################\n",
        "\n",
        "        return pred\n",
        "    \n",
        "    def loss(self, pred, link_label):\n",
        "        return self.loss_fn(pred, link_label)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRV81vcuRns1"
      },
      "source": [
        "from sklearn.metrics import *\n",
        "\n",
        "def train(model, dataloaders, optimizer, args):\n",
        "    val_max = 0\n",
        "    best_model = model\n",
        "\n",
        "    for epoch in range(1, args[\"epochs\"]):\n",
        "        for i, batch in enumerate(dataloaders['train']):\n",
        "            \n",
        "            batch.to(args[\"device\"])\n",
        "\n",
        "            ############# Your code here #############\n",
        "            ## (~6 lines of code)\n",
        "            ## Note\n",
        "            ## 1. Zero grad the optimizer\n",
        "            ## 2. Compute loss and backpropagate\n",
        "            ## 3. Update the model parameters\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            p=model(batch)\n",
        "            loss = model.loss(p,batch.edge_label.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            ##########################################\n",
        "\n",
        "            log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Loss: {}'\n",
        "            score_train = test(model, dataloaders['train'], args)\n",
        "            score_val = test(model, dataloaders['val'], args)\n",
        "            score_test = test(model, dataloaders['test'], args)\n",
        "\n",
        "            print(log.format(epoch, score_train, score_val, score_test, loss.item()))\n",
        "            if val_max < score_val:\n",
        "                val_max = score_val\n",
        "                best_model = copy.deepcopy(model)\n",
        "    return best_model\n",
        "\n",
        "def test(model, dataloader, args):\n",
        "    model.eval()\n",
        "    \n",
        "    score = 0\n",
        "\n",
        "    ############# Your code here #############\n",
        "    ## (~5 lines of code)\n",
        "    ## Note\n",
        "    ## 1. Loop through batches in the dataloader\n",
        "    ## 2. Feed the batch to the model\n",
        "    ## 3. Feed the model output to sigmoid\n",
        "    ## 4. Compute the ROC-AUC score by using sklearn roc_auc_score function\n",
        "    ## 5. Edge labels are stored in batch.edge_label\n",
        "    for batch in dataloader:\n",
        "      batch.to(args['device'])\n",
        "      p=model(batch)\n",
        "      p=torch.sigmoid(p)\n",
        "      p=p.cpu().detach().numpy()  #这后面跟的一堆是输出让我这么干的……\n",
        "      label=batch.edge_label.cpu().detach().numpy()\n",
        "      score+=roc_auc_score(label,p)\n",
        "    score=score/len(dataloader)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    ##########################################\n",
        " \n",
        "    return score"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzxR0B1dVvsk"
      },
      "source": [
        "# Please don't change any parameters\n",
        "args = {\n",
        "    \"device\" : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    \"hidden_dim\" : 128,\n",
        "    \"epochs\" : 200,\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2vS-cs3V0Ag",
        "outputId": "dee4508e-bce8-40eb-d44a-20e86d260bae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pyg_dataset = Planetoid('./tmp/cora', 'Cora')\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "dataset = GraphDataset(\n",
        "        graphs,\n",
        "        task='link_pred',\n",
        "        edge_train_mode=\"disjoint\"\n",
        "    )\n",
        "datasets = {}\n",
        "datasets['train'], datasets['val'], datasets['test']= dataset.split(\n",
        "            transductive=True, split_ratio=[0.85, 0.05, 0.1])\n",
        "input_dim = datasets['train'].num_node_features\n",
        "num_classes = datasets['train'].num_edge_labels\n",
        "\n",
        "model = LinkPredModel(input_dim, args[\"hidden_dim\"], num_classes).to(args[\"device\"])\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "dataloaders = {split: DataLoader(\n",
        "            ds, collate_fn=Batch.collate([]),\n",
        "            batch_size=1, shuffle=(split=='train'))\n",
        "            for split, ds in datasets.items()}\n",
        "best_model = train(model, dataloaders, optimizer, args)\n",
        "log = \"Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\"\n",
        "best_train_roc = test(best_model, dataloaders['train'], args)\n",
        "best_val_roc = test(best_model, dataloaders['val'], args)\n",
        "best_test_roc = test(best_model, dataloaders['test'], args)\n",
        "print(log.format(best_train_roc, best_val_roc, best_test_roc))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001, Train: 0.5128, Val: 0.4734, Test: 0.4904, Loss: 0.6930962800979614\n",
            "Epoch: 002, Train: 0.5152, Val: 0.4739, Test: 0.4910, Loss: 0.6931557655334473\n",
            "Epoch: 003, Train: 0.5064, Val: 0.4745, Test: 0.4918, Loss: 0.6931293606758118\n",
            "Epoch: 004, Train: 0.5063, Val: 0.4752, Test: 0.4927, Loss: 0.6931201815605164\n",
            "Epoch: 005, Train: 0.5146, Val: 0.4763, Test: 0.4940, Loss: 0.6931753754615784\n",
            "Epoch: 006, Train: 0.5208, Val: 0.4777, Test: 0.4954, Loss: 0.693088710308075\n",
            "Epoch: 007, Train: 0.5239, Val: 0.4788, Test: 0.4970, Loss: 0.6930528879165649\n",
            "Epoch: 008, Train: 0.5278, Val: 0.4803, Test: 0.4987, Loss: 0.6931006908416748\n",
            "Epoch: 009, Train: 0.5182, Val: 0.4818, Test: 0.5005, Loss: 0.6929613351821899\n",
            "Epoch: 010, Train: 0.5218, Val: 0.4830, Test: 0.5023, Loss: 0.6930450797080994\n",
            "Epoch: 011, Train: 0.5309, Val: 0.4844, Test: 0.5041, Loss: 0.6929472088813782\n",
            "Epoch: 012, Train: 0.5302, Val: 0.4860, Test: 0.5055, Loss: 0.6929320693016052\n",
            "Epoch: 013, Train: 0.5474, Val: 0.4873, Test: 0.5072, Loss: 0.692922055721283\n",
            "Epoch: 014, Train: 0.5433, Val: 0.4886, Test: 0.5089, Loss: 0.6930070519447327\n",
            "Epoch: 015, Train: 0.5320, Val: 0.4899, Test: 0.5105, Loss: 0.6929661631584167\n",
            "Epoch: 016, Train: 0.5524, Val: 0.4917, Test: 0.5122, Loss: 0.6929128170013428\n",
            "Epoch: 017, Train: 0.5464, Val: 0.4930, Test: 0.5137, Loss: 0.692999005317688\n",
            "Epoch: 018, Train: 0.5553, Val: 0.4944, Test: 0.5153, Loss: 0.6929060220718384\n",
            "Epoch: 019, Train: 0.5695, Val: 0.4956, Test: 0.5168, Loss: 0.6929437518119812\n",
            "Epoch: 020, Train: 0.5743, Val: 0.4971, Test: 0.5183, Loss: 0.6928229928016663\n",
            "Epoch: 021, Train: 0.5596, Val: 0.4982, Test: 0.5197, Loss: 0.6928449273109436\n",
            "Epoch: 022, Train: 0.5655, Val: 0.4996, Test: 0.5210, Loss: 0.6928042769432068\n",
            "Epoch: 023, Train: 0.5694, Val: 0.5008, Test: 0.5222, Loss: 0.6927818059921265\n",
            "Epoch: 024, Train: 0.5602, Val: 0.5025, Test: 0.5230, Loss: 0.6927734017372131\n",
            "Epoch: 025, Train: 0.5719, Val: 0.5038, Test: 0.5240, Loss: 0.6927854418754578\n",
            "Epoch: 026, Train: 0.5751, Val: 0.5053, Test: 0.5248, Loss: 0.6927480697631836\n",
            "Epoch: 027, Train: 0.5840, Val: 0.5070, Test: 0.5256, Loss: 0.69272780418396\n",
            "Epoch: 028, Train: 0.5910, Val: 0.5081, Test: 0.5265, Loss: 0.6926445960998535\n",
            "Epoch: 029, Train: 0.5869, Val: 0.5096, Test: 0.5273, Loss: 0.6926316618919373\n",
            "Epoch: 030, Train: 0.5994, Val: 0.5105, Test: 0.5279, Loss: 0.6924691200256348\n",
            "Epoch: 031, Train: 0.5762, Val: 0.5122, Test: 0.5286, Loss: 0.692628026008606\n",
            "Epoch: 032, Train: 0.5883, Val: 0.5133, Test: 0.5291, Loss: 0.6924701929092407\n",
            "Epoch: 033, Train: 0.5915, Val: 0.5144, Test: 0.5295, Loss: 0.6925780177116394\n",
            "Epoch: 034, Train: 0.6028, Val: 0.5153, Test: 0.5303, Loss: 0.6924570798873901\n",
            "Epoch: 035, Train: 0.6097, Val: 0.5167, Test: 0.5306, Loss: 0.6923602223396301\n",
            "Epoch: 036, Train: 0.5973, Val: 0.5182, Test: 0.5309, Loss: 0.6921179294586182\n",
            "Epoch: 037, Train: 0.5999, Val: 0.5197, Test: 0.5312, Loss: 0.6920967102050781\n",
            "Epoch: 038, Train: 0.5989, Val: 0.5211, Test: 0.5316, Loss: 0.6920903921127319\n",
            "Epoch: 039, Train: 0.5984, Val: 0.5225, Test: 0.5319, Loss: 0.6920005679130554\n",
            "Epoch: 040, Train: 0.6084, Val: 0.5240, Test: 0.5320, Loss: 0.6920859813690186\n",
            "Epoch: 041, Train: 0.6070, Val: 0.5255, Test: 0.5323, Loss: 0.6919199228286743\n",
            "Epoch: 042, Train: 0.6221, Val: 0.5268, Test: 0.5326, Loss: 0.6918549537658691\n",
            "Epoch: 043, Train: 0.6192, Val: 0.5281, Test: 0.5330, Loss: 0.6915478110313416\n",
            "Epoch: 044, Train: 0.6099, Val: 0.5295, Test: 0.5333, Loss: 0.6912933588027954\n",
            "Epoch: 045, Train: 0.6194, Val: 0.5309, Test: 0.5336, Loss: 0.6913715600967407\n",
            "Epoch: 046, Train: 0.6209, Val: 0.5318, Test: 0.5339, Loss: 0.6910300254821777\n",
            "Epoch: 047, Train: 0.6156, Val: 0.5328, Test: 0.5344, Loss: 0.6910026669502258\n",
            "Epoch: 048, Train: 0.6185, Val: 0.5339, Test: 0.5347, Loss: 0.6908661127090454\n",
            "Epoch: 049, Train: 0.6162, Val: 0.5348, Test: 0.5352, Loss: 0.6908126473426819\n",
            "Epoch: 050, Train: 0.6128, Val: 0.5368, Test: 0.5356, Loss: 0.690486490726471\n",
            "Epoch: 051, Train: 0.6203, Val: 0.5383, Test: 0.5360, Loss: 0.6904374957084656\n",
            "Epoch: 052, Train: 0.6191, Val: 0.5397, Test: 0.5367, Loss: 0.6901389956474304\n",
            "Epoch: 053, Train: 0.6239, Val: 0.5408, Test: 0.5375, Loss: 0.68989098072052\n",
            "Epoch: 054, Train: 0.6166, Val: 0.5422, Test: 0.5383, Loss: 0.6895382404327393\n",
            "Epoch: 055, Train: 0.6167, Val: 0.5433, Test: 0.5387, Loss: 0.6889854669570923\n",
            "Epoch: 056, Train: 0.6237, Val: 0.5446, Test: 0.5391, Loss: 0.6893242597579956\n",
            "Epoch: 057, Train: 0.6171, Val: 0.5459, Test: 0.5398, Loss: 0.6885757446289062\n",
            "Epoch: 058, Train: 0.6225, Val: 0.5471, Test: 0.5407, Loss: 0.6880645155906677\n",
            "Epoch: 059, Train: 0.6306, Val: 0.5482, Test: 0.5417, Loss: 0.6878913640975952\n",
            "Epoch: 060, Train: 0.6285, Val: 0.5490, Test: 0.5425, Loss: 0.6878479719161987\n",
            "Epoch: 061, Train: 0.6261, Val: 0.5499, Test: 0.5436, Loss: 0.6869406700134277\n",
            "Epoch: 062, Train: 0.6179, Val: 0.5509, Test: 0.5447, Loss: 0.6866723299026489\n",
            "Epoch: 063, Train: 0.6319, Val: 0.5517, Test: 0.5460, Loss: 0.6858271956443787\n",
            "Epoch: 064, Train: 0.6142, Val: 0.5528, Test: 0.5473, Loss: 0.6849573254585266\n",
            "Epoch: 065, Train: 0.6320, Val: 0.5538, Test: 0.5488, Loss: 0.685670793056488\n",
            "Epoch: 066, Train: 0.6228, Val: 0.5551, Test: 0.5505, Loss: 0.6847700476646423\n",
            "Epoch: 067, Train: 0.6212, Val: 0.5566, Test: 0.5525, Loss: 0.6847448945045471\n",
            "Epoch: 068, Train: 0.6205, Val: 0.5580, Test: 0.5547, Loss: 0.6824020147323608\n",
            "Epoch: 069, Train: 0.6334, Val: 0.5595, Test: 0.5570, Loss: 0.6814620494842529\n",
            "Epoch: 070, Train: 0.6358, Val: 0.5611, Test: 0.5597, Loss: 0.6810488700866699\n",
            "Epoch: 071, Train: 0.6349, Val: 0.5634, Test: 0.5624, Loss: 0.6786059141159058\n",
            "Epoch: 072, Train: 0.6385, Val: 0.5655, Test: 0.5654, Loss: 0.6787777543067932\n",
            "Epoch: 073, Train: 0.6455, Val: 0.5682, Test: 0.5688, Loss: 0.6775116324424744\n",
            "Epoch: 074, Train: 0.6386, Val: 0.5713, Test: 0.5726, Loss: 0.6748760342597961\n",
            "Epoch: 075, Train: 0.6417, Val: 0.5758, Test: 0.5781, Loss: 0.6746575832366943\n",
            "Epoch: 076, Train: 0.6552, Val: 0.5821, Test: 0.5849, Loss: 0.6745275855064392\n",
            "Epoch: 077, Train: 0.6503, Val: 0.5889, Test: 0.5929, Loss: 0.6708798408508301\n",
            "Epoch: 078, Train: 0.6600, Val: 0.5978, Test: 0.6025, Loss: 0.6685944199562073\n",
            "Epoch: 079, Train: 0.6724, Val: 0.6101, Test: 0.6146, Loss: 0.6680306196212769\n",
            "Epoch: 080, Train: 0.6816, Val: 0.6253, Test: 0.6281, Loss: 0.6656329035758972\n",
            "Epoch: 081, Train: 0.6853, Val: 0.6369, Test: 0.6446, Loss: 0.6630868911743164\n",
            "Epoch: 082, Train: 0.6934, Val: 0.6492, Test: 0.6577, Loss: 0.6582782864570618\n",
            "Epoch: 083, Train: 0.6901, Val: 0.6641, Test: 0.6693, Loss: 0.6589422821998596\n",
            "Epoch: 084, Train: 0.7134, Val: 0.6766, Test: 0.6828, Loss: 0.6529191732406616\n",
            "Epoch: 085, Train: 0.7161, Val: 0.6873, Test: 0.6951, Loss: 0.6541723608970642\n",
            "Epoch: 086, Train: 0.7042, Val: 0.6946, Test: 0.7068, Loss: 0.6495190858840942\n",
            "Epoch: 087, Train: 0.7224, Val: 0.6990, Test: 0.7166, Loss: 0.6476494669914246\n",
            "Epoch: 088, Train: 0.7259, Val: 0.7020, Test: 0.7253, Loss: 0.6423709988594055\n",
            "Epoch: 089, Train: 0.7138, Val: 0.7018, Test: 0.7301, Loss: 0.6371253132820129\n",
            "Epoch: 090, Train: 0.7159, Val: 0.7020, Test: 0.7330, Loss: 0.6357108354568481\n",
            "Epoch: 091, Train: 0.7229, Val: 0.7023, Test: 0.7351, Loss: 0.6293575167655945\n",
            "Epoch: 092, Train: 0.7251, Val: 0.7029, Test: 0.7369, Loss: 0.6301663517951965\n",
            "Epoch: 093, Train: 0.7236, Val: 0.7039, Test: 0.7383, Loss: 0.6197553873062134\n",
            "Epoch: 094, Train: 0.7398, Val: 0.7040, Test: 0.7395, Loss: 0.6155787110328674\n",
            "Epoch: 095, Train: 0.7426, Val: 0.7038, Test: 0.7403, Loss: 0.6118291616439819\n",
            "Epoch: 096, Train: 0.7389, Val: 0.7034, Test: 0.7410, Loss: 0.6097577810287476\n",
            "Epoch: 097, Train: 0.7320, Val: 0.7044, Test: 0.7419, Loss: 0.6050819158554077\n",
            "Epoch: 098, Train: 0.7496, Val: 0.7052, Test: 0.7426, Loss: 0.6154427528381348\n",
            "Epoch: 099, Train: 0.7550, Val: 0.7050, Test: 0.7427, Loss: 0.6330071091651917\n",
            "Epoch: 100, Train: 0.7528, Val: 0.7053, Test: 0.7428, Loss: 0.6176688075065613\n",
            "Epoch: 101, Train: 0.7476, Val: 0.7063, Test: 0.7432, Loss: 0.6197581887245178\n",
            "Epoch: 102, Train: 0.7587, Val: 0.7103, Test: 0.7456, Loss: 0.6135038733482361\n",
            "Epoch: 103, Train: 0.7693, Val: 0.7136, Test: 0.7467, Loss: 0.5931077003479004\n",
            "Epoch: 104, Train: 0.7690, Val: 0.7142, Test: 0.7470, Loss: 0.6051799654960632\n",
            "Epoch: 105, Train: 0.7677, Val: 0.7138, Test: 0.7467, Loss: 0.5898500680923462\n",
            "Epoch: 106, Train: 0.7746, Val: 0.7127, Test: 0.7459, Loss: 0.5963261127471924\n",
            "Epoch: 107, Train: 0.7757, Val: 0.7132, Test: 0.7456, Loss: 0.5961434245109558\n",
            "Epoch: 108, Train: 0.7837, Val: 0.7154, Test: 0.7463, Loss: 0.587583065032959\n",
            "Epoch: 109, Train: 0.7820, Val: 0.7182, Test: 0.7467, Loss: 0.5938105583190918\n",
            "Epoch: 110, Train: 0.7838, Val: 0.7199, Test: 0.7467, Loss: 0.5868326425552368\n",
            "Epoch: 111, Train: 0.7879, Val: 0.7201, Test: 0.7466, Loss: 0.5954247713088989\n",
            "Epoch: 112, Train: 0.8022, Val: 0.7200, Test: 0.7465, Loss: 0.5856536626815796\n",
            "Epoch: 113, Train: 0.7764, Val: 0.7206, Test: 0.7465, Loss: 0.5829118490219116\n",
            "Epoch: 114, Train: 0.7910, Val: 0.7221, Test: 0.7465, Loss: 0.5844021439552307\n",
            "Epoch: 115, Train: 0.7924, Val: 0.7230, Test: 0.7465, Loss: 0.5858141779899597\n",
            "Epoch: 116, Train: 0.7914, Val: 0.7228, Test: 0.7464, Loss: 0.5757760405540466\n",
            "Epoch: 117, Train: 0.7949, Val: 0.7235, Test: 0.7464, Loss: 0.5845813751220703\n",
            "Epoch: 118, Train: 0.8033, Val: 0.7244, Test: 0.7465, Loss: 0.576015055179596\n",
            "Epoch: 119, Train: 0.7978, Val: 0.7255, Test: 0.7467, Loss: 0.5757353901863098\n",
            "Epoch: 120, Train: 0.8017, Val: 0.7267, Test: 0.7469, Loss: 0.5705562233924866\n",
            "Epoch: 121, Train: 0.8094, Val: 0.7265, Test: 0.7466, Loss: 0.5873842239379883\n",
            "Epoch: 122, Train: 0.8107, Val: 0.7273, Test: 0.7465, Loss: 0.5709605813026428\n",
            "Epoch: 123, Train: 0.8165, Val: 0.7289, Test: 0.7469, Loss: 0.5781273245811462\n",
            "Epoch: 124, Train: 0.8145, Val: 0.7303, Test: 0.7475, Loss: 0.5727348923683167\n",
            "Epoch: 125, Train: 0.8230, Val: 0.7322, Test: 0.7484, Loss: 0.5637913346290588\n",
            "Epoch: 126, Train: 0.8194, Val: 0.7336, Test: 0.7486, Loss: 0.5661000609397888\n",
            "Epoch: 127, Train: 0.8218, Val: 0.7330, Test: 0.7487, Loss: 0.5666429996490479\n",
            "Epoch: 128, Train: 0.8250, Val: 0.7305, Test: 0.7476, Loss: 0.567294716835022\n",
            "Epoch: 129, Train: 0.8169, Val: 0.7298, Test: 0.7470, Loss: 0.5670831799507141\n",
            "Epoch: 130, Train: 0.8254, Val: 0.7318, Test: 0.7484, Loss: 0.5674904584884644\n",
            "Epoch: 131, Train: 0.8238, Val: 0.7352, Test: 0.7503, Loss: 0.564242422580719\n",
            "Epoch: 132, Train: 0.8356, Val: 0.7376, Test: 0.7519, Loss: 0.5563193559646606\n",
            "Epoch: 133, Train: 0.8386, Val: 0.7390, Test: 0.7528, Loss: 0.5625125169754028\n",
            "Epoch: 134, Train: 0.8354, Val: 0.7393, Test: 0.7532, Loss: 0.550665020942688\n",
            "Epoch: 135, Train: 0.8315, Val: 0.7386, Test: 0.7531, Loss: 0.5604888796806335\n",
            "Epoch: 136, Train: 0.8355, Val: 0.7378, Test: 0.7527, Loss: 0.547764241695404\n",
            "Epoch: 137, Train: 0.8315, Val: 0.7385, Test: 0.7525, Loss: 0.5514487624168396\n",
            "Epoch: 138, Train: 0.8442, Val: 0.7394, Test: 0.7530, Loss: 0.557962954044342\n",
            "Epoch: 139, Train: 0.8313, Val: 0.7417, Test: 0.7555, Loss: 0.5466469526290894\n",
            "Epoch: 140, Train: 0.8374, Val: 0.7443, Test: 0.7573, Loss: 0.5419294834136963\n",
            "Epoch: 141, Train: 0.8476, Val: 0.7455, Test: 0.7580, Loss: 0.5544627904891968\n",
            "Epoch: 142, Train: 0.8456, Val: 0.7451, Test: 0.7573, Loss: 0.5535975098609924\n",
            "Epoch: 143, Train: 0.8442, Val: 0.7456, Test: 0.7565, Loss: 0.5403804183006287\n",
            "Epoch: 144, Train: 0.8492, Val: 0.7472, Test: 0.7576, Loss: 0.5580313205718994\n",
            "Epoch: 145, Train: 0.8595, Val: 0.7506, Test: 0.7601, Loss: 0.541839063167572\n",
            "Epoch: 146, Train: 0.8596, Val: 0.7545, Test: 0.7629, Loss: 0.546196460723877\n",
            "Epoch: 147, Train: 0.8634, Val: 0.7559, Test: 0.7635, Loss: 0.5454010367393494\n",
            "Epoch: 148, Train: 0.8610, Val: 0.7584, Test: 0.7650, Loss: 0.5457074642181396\n",
            "Epoch: 149, Train: 0.8684, Val: 0.7580, Test: 0.7646, Loss: 0.5421448349952698\n",
            "Epoch: 150, Train: 0.8626, Val: 0.7550, Test: 0.7616, Loss: 0.5315783619880676\n",
            "Epoch: 151, Train: 0.8692, Val: 0.7600, Test: 0.7655, Loss: 0.5404517650604248\n",
            "Epoch: 152, Train: 0.8748, Val: 0.7653, Test: 0.7697, Loss: 0.5289267301559448\n",
            "Epoch: 153, Train: 0.8672, Val: 0.7657, Test: 0.7690, Loss: 0.5341324210166931\n",
            "Epoch: 154, Train: 0.8718, Val: 0.7687, Test: 0.7713, Loss: 0.5332127809524536\n",
            "Epoch: 155, Train: 0.8772, Val: 0.7718, Test: 0.7735, Loss: 0.5333873629570007\n",
            "Epoch: 156, Train: 0.8811, Val: 0.7716, Test: 0.7727, Loss: 0.5357232093811035\n",
            "Epoch: 157, Train: 0.8817, Val: 0.7722, Test: 0.7732, Loss: 0.5244155526161194\n",
            "Epoch: 158, Train: 0.8770, Val: 0.7779, Test: 0.7771, Loss: 0.5355200171470642\n",
            "Epoch: 159, Train: 0.8890, Val: 0.7817, Test: 0.7791, Loss: 0.5195046663284302\n",
            "Epoch: 160, Train: 0.8892, Val: 0.7832, Test: 0.7799, Loss: 0.5234611630439758\n",
            "Epoch: 161, Train: 0.8876, Val: 0.7833, Test: 0.7807, Loss: 0.5254485607147217\n",
            "Epoch: 162, Train: 0.8905, Val: 0.7812, Test: 0.7800, Loss: 0.529724657535553\n",
            "Epoch: 163, Train: 0.8899, Val: 0.7811, Test: 0.7799, Loss: 0.5243817567825317\n",
            "Epoch: 164, Train: 0.8896, Val: 0.7839, Test: 0.7814, Loss: 0.5151559710502625\n",
            "Epoch: 165, Train: 0.8969, Val: 0.7860, Test: 0.7819, Loss: 0.5203158855438232\n",
            "Epoch: 166, Train: 0.8898, Val: 0.7866, Test: 0.7823, Loss: 0.505596935749054\n",
            "Epoch: 167, Train: 0.8945, Val: 0.7864, Test: 0.7826, Loss: 0.511933445930481\n",
            "Epoch: 168, Train: 0.9013, Val: 0.7849, Test: 0.7820, Loss: 0.5138188004493713\n",
            "Epoch: 169, Train: 0.8956, Val: 0.7851, Test: 0.7822, Loss: 0.5120844841003418\n",
            "Epoch: 170, Train: 0.9022, Val: 0.7878, Test: 0.7834, Loss: 0.5131875276565552\n",
            "Epoch: 171, Train: 0.8990, Val: 0.7902, Test: 0.7845, Loss: 0.5071584582328796\n",
            "Epoch: 172, Train: 0.8997, Val: 0.7913, Test: 0.7844, Loss: 0.5153719782829285\n",
            "Epoch: 173, Train: 0.9036, Val: 0.7896, Test: 0.7843, Loss: 0.517483651638031\n",
            "Epoch: 174, Train: 0.8960, Val: 0.7863, Test: 0.7822, Loss: 0.5147159099578857\n",
            "Epoch: 175, Train: 0.8955, Val: 0.7839, Test: 0.7806, Loss: 0.5086250901222229\n",
            "Epoch: 176, Train: 0.9054, Val: 0.7872, Test: 0.7824, Loss: 0.5125852227210999\n",
            "Epoch: 177, Train: 0.9071, Val: 0.7908, Test: 0.7841, Loss: 0.5121587514877319\n",
            "Epoch: 178, Train: 0.9078, Val: 0.7918, Test: 0.7828, Loss: 0.5063673257827759\n",
            "Epoch: 179, Train: 0.9086, Val: 0.7920, Test: 0.7835, Loss: 0.49482518434524536\n",
            "Epoch: 180, Train: 0.9168, Val: 0.7904, Test: 0.7836, Loss: 0.5072249174118042\n",
            "Epoch: 181, Train: 0.9094, Val: 0.7859, Test: 0.7808, Loss: 0.5139164328575134\n",
            "Epoch: 182, Train: 0.9156, Val: 0.7866, Test: 0.7809, Loss: 0.5031707286834717\n",
            "Epoch: 183, Train: 0.9096, Val: 0.7898, Test: 0.7818, Loss: 0.49963539838790894\n",
            "Epoch: 184, Train: 0.9138, Val: 0.7914, Test: 0.7816, Loss: 0.5005974769592285\n",
            "Epoch: 185, Train: 0.9118, Val: 0.7925, Test: 0.7826, Loss: 0.50493323802948\n",
            "Epoch: 186, Train: 0.9161, Val: 0.7911, Test: 0.7831, Loss: 0.4961336851119995\n",
            "Epoch: 187, Train: 0.9210, Val: 0.7896, Test: 0.7820, Loss: 0.5031124353408813\n",
            "Epoch: 188, Train: 0.9174, Val: 0.7936, Test: 0.7839, Loss: 0.49023622274398804\n",
            "Epoch: 189, Train: 0.9150, Val: 0.7956, Test: 0.7839, Loss: 0.5035056471824646\n",
            "Epoch: 190, Train: 0.9173, Val: 0.7955, Test: 0.7834, Loss: 0.49647143483161926\n",
            "Epoch: 191, Train: 0.9193, Val: 0.7934, Test: 0.7833, Loss: 0.4990619719028473\n",
            "Epoch: 192, Train: 0.9229, Val: 0.7912, Test: 0.7823, Loss: 0.5021169781684875\n",
            "Epoch: 193, Train: 0.9245, Val: 0.7898, Test: 0.7815, Loss: 0.49547967314720154\n",
            "Epoch: 194, Train: 0.9196, Val: 0.7927, Test: 0.7832, Loss: 0.4977237582206726\n",
            "Epoch: 195, Train: 0.9283, Val: 0.7958, Test: 0.7841, Loss: 0.49992409348487854\n",
            "Epoch: 196, Train: 0.9281, Val: 0.7965, Test: 0.7843, Loss: 0.48530852794647217\n",
            "Epoch: 197, Train: 0.9258, Val: 0.7967, Test: 0.7846, Loss: 0.49825620651245117\n",
            "Epoch: 198, Train: 0.9240, Val: 0.7942, Test: 0.7840, Loss: 0.4887050688266754\n",
            "Epoch: 199, Train: 0.9256, Val: 0.7918, Test: 0.7829, Loss: 0.4881899654865265\n",
            "Train: 0.9314, Val: 0.7967, Test: 0.7846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-keQbTIblum0"
      },
      "source": [
        ""
      ]
    }
  ]
}