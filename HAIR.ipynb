{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBMayQyuXEa3zTVSkX6WHJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2359181042/GNN_cs224w/blob/main/HAIR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1e7hxUQBz5Y",
        "outputId": "420ae6f6-a2c2-4908-94c5-51d0ef5fbeae"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-geometric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.6MB 5.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 5.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 35.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QokfRQMB-EK",
        "outputId": "50f566ec-f920-4287-813e-570e0a4acc9b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "TIME_WINDOW = 24\n",
        "PRED_TIME = 12\n",
        "DATA_PATH = 'gdrive/My Drive/HAir/'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOR5V69sCNu7"
      },
      "source": [
        "class trainDataset(Data.Dataset):\n",
        "    def __init__(self, transform=None, train=True):\n",
        "        with open(os.path.join(DATA_PATH,'city_train.txt'), 'r') as f:\n",
        "            self.cities = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'jiaxing_train.txt'), 'r') as f:\n",
        "            self.jiaxing = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'shanghai_train.txt'), 'r') as f:\n",
        "            self.shanghai = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'suzhou_train.txt'), 'r') as f:\n",
        "            self.suzhou = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'stations.txt'), 'r') as f:\n",
        "            self.stations = json.load(f)\n",
        "\n",
        "    def GetCityData(self,city_name,city_source,index):\n",
        "        station_list = self.stations[city_name]\n",
        "        city_aqi = []\n",
        "        city_y = []\n",
        "        for x in station_list:\n",
        "            city_aqi.append(city_source[x][index][:TIME_WINDOW])\n",
        "            city_y.append(city_source[x][index][TIME_WINDOW:])\n",
        "\n",
        "        city_aqi = torch.FloatTensor(city_aqi)\n",
        "        city_y = torch.FloatTensor(city_y)\n",
        "        city_sim = torch.FloatTensor(city_source['sim'][index])\n",
        "        city_conn = torch.tensor(city_source['conn'])\n",
        "        city_weather = torch.FloatTensor(city_source['weather'][index])\n",
        "        city_for = torch.FloatTensor(city_source['weather_for'][index])\n",
        "        city_poi = torch.FloatTensor(city_source['poi'])\n",
        "\n",
        "        city_data = [city_aqi, city_conn, city_poi, city_sim,\n",
        "                city_weather, city_for, city_y]\n",
        "\t\t\n",
        "        return city_data\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        jiaxing_data = self.GetCityData('jiaxing',self.jiaxing,index)\n",
        "        shanghai_data = self.GetCityData('shanghai',self.shanghai,index)\n",
        "        suzhou_data = self.GetCityData('suzhou',self.suzhou,index)\n",
        "\n",
        "        cities_aqi = torch.FloatTensor(self.cities['aqi'][index])\n",
        "        cities_conn = torch.tensor(self.cities['conn'])\n",
        "        cities_weather = torch.FloatTensor(self.cities['weather'][index])\n",
        "        cities_sim = torch.FloatTensor(self.cities['sim'][index])\n",
        "\n",
        "        cities_data = [cities_aqi, cities_conn,cities_sim,cities_weather]\n",
        "        \n",
        "        return cities_data,jiaxing_data,shanghai_data,suzhou_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.shanghai['weather'])\n",
        "\n",
        "class valDataset(Data.Dataset):\n",
        "    def __init__(self, transform=None, train=True):\n",
        "        with open(os.path.join(DATA_PATH,'city_val.txt'), 'r') as f:\n",
        "            self.cities = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'jiaxing_val.txt'), 'r') as f:\n",
        "            self.jiaxing = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'shanghai_val.txt'), 'r') as f:\n",
        "            self.shanghai = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'suzhou_val.txt'), 'r') as f:\n",
        "            self.suzhou = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'stations.txt'), 'r') as f:\n",
        "            self.stations = json.load(f)\n",
        "\n",
        "    def GetCityData(self,city_name,city_source,index):\n",
        "        station_list = self.stations[city_name]\n",
        "        city_aqi = []\n",
        "        city_y = []\n",
        "        for x in station_list:\n",
        "            city_aqi.append(city_source[x][index][:TIME_WINDOW])\n",
        "            city_y.append(city_source[x][index][TIME_WINDOW:])\n",
        "\n",
        "        city_aqi = torch.FloatTensor(city_aqi)\n",
        "        city_y = torch.FloatTensor(city_y)\n",
        "        city_sim = torch.FloatTensor(city_source['sim'][index])\n",
        "        city_conn = torch.tensor(city_source['conn'])\n",
        "        city_weather = torch.FloatTensor(city_source['weather'][index])\n",
        "        city_for = torch.FloatTensor(city_source['weather_for'][index])\n",
        "        city_poi = torch.FloatTensor(city_source['poi'])\n",
        "\n",
        "        city_data = [city_aqi, city_conn, city_poi, city_sim,\n",
        "                city_weather, city_for, city_y]\n",
        "\t\t\n",
        "        return city_data\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        jiaxing_data = self.GetCityData('jiaxing',self.jiaxing,index)\n",
        "        shanghai_data = self.GetCityData('shanghai',self.shanghai,index)\n",
        "        suzhou_data = self.GetCityData('suzhou',self.suzhou,index)\n",
        "\n",
        "        cities_aqi = torch.FloatTensor(self.cities['aqi'][index])\n",
        "        cities_conn = torch.tensor(self.cities['conn'])\n",
        "        cities_weather = torch.FloatTensor(self.cities['weather'][index])\n",
        "        cities_sim = torch.FloatTensor(self.cities['sim'][index])\n",
        "\n",
        "        cities_data = [cities_aqi, cities_conn,cities_sim,cities_weather]\n",
        "        \n",
        "        return cities_data,jiaxing_data,shanghai_data,suzhou_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.shanghai['weather'])\n",
        "\n",
        "\n",
        "class testDataset(Data.Dataset):\n",
        "    def __init__(self, transform=None, train=True):\n",
        "        with open(os.path.join(DATA_PATH,'city_test.txt'), 'r') as f:\n",
        "            self.cities = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'jiaxing_test.txt'), 'r') as f:\n",
        "            self.jiaxing = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'shanghai_test.txt'), 'r') as f:\n",
        "            self.shanghai = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'suzhou_test.txt'), 'r') as f:\n",
        "            self.suzhou = json.load(f)\n",
        "\n",
        "        with open(os.path.join(DATA_PATH,'stations.txt'), 'r') as f:\n",
        "            self.stations = json.load(f)\n",
        "\n",
        "    def GetCityData(self,city_name,city_source,index):\n",
        "        station_list = self.stations[city_name]\n",
        "        city_aqi = []\n",
        "        city_y = []\n",
        "        for x in station_list:\n",
        "            city_aqi.append(city_source[x][index][:TIME_WINDOW])\n",
        "            city_y.append(city_source[x][index][TIME_WINDOW:])\n",
        "\n",
        "        city_aqi = torch.FloatTensor(city_aqi)\n",
        "        city_y = torch.FloatTensor(city_y)\n",
        "        city_sim = torch.FloatTensor(city_source['sim'][index])\n",
        "        city_conn = torch.tensor(city_source['conn'])\n",
        "        city_weather = torch.FloatTensor(city_source['weather'][index])\n",
        "        city_for = torch.FloatTensor(city_source['weather_for'][index])\n",
        "        city_poi = torch.FloatTensor(city_source['poi'])\n",
        "\n",
        "        city_data = [city_aqi, city_conn, city_poi, city_sim,\n",
        "                city_weather, city_for, city_y]\n",
        "\t\t\n",
        "        return city_data\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        jiaxing_data = self.GetCityData('jiaxing',self.jiaxing,index)\n",
        "        shanghai_data = self.GetCityData('shanghai',self.shanghai,index)\n",
        "        suzhou_data = self.GetCityData('suzhou',self.suzhou,index)\n",
        "\n",
        "        cities_aqi = torch.FloatTensor(self.cities['aqi'][index])\n",
        "        cities_conn = torch.tensor(self.cities['conn'])\n",
        "        cities_weather = torch.FloatTensor(self.cities['weather'][index])\n",
        "        cities_sim = torch.FloatTensor(self.cities['sim'][index])\n",
        "\n",
        "        cities_data = [cities_aqi, cities_conn,cities_sim,cities_weather]\n",
        "        \n",
        "        return cities_data,jiaxing_data,shanghai_data,suzhou_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.shanghai['weather'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdpyLPi3Cc1B"
      },
      "source": [
        "import argparse\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "\n",
        "#from dataset import testDataset, trainDataset, valDataset\n",
        "#from model import CityModel, GlobalModel\n",
        "\n",
        "from torch_geometric.nn import MetaLayer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "N7PdsDsICh7H",
        "outputId": "f65bc2e7-4968-477d-8bcc-402b959bed7b"
      },
      "source": [
        "parser = argparse.ArgumentParser(description='Multi-city AQI forecasting')\n",
        "parser.add_argument('--device', type=str, default='cuda', help='')\n",
        "parser.add_argument('--run_times', type=int, default=5, help='')\n",
        "parser.add_argument('--epoch', type=int, default=300, help='')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='')\n",
        "parser.add_argument('--city_num', type=int, default=10, help='')\n",
        "parser.add_argument('--gnn_h', type=int, default=32, help='')\n",
        "parser.add_argument('--rnn_h', type=int, default=64, help='')\n",
        "parser.add_argument('--rnn_l', type=int, default=1, help='')\n",
        "parser.add_argument('--aqi_em', type=int, default=16, help='')\n",
        "parser.add_argument('--poi_em', type=int, default=8, help='poi embedding')\n",
        "parser.add_argument('--wea_em', type=int, default=12, help='wea embedding')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='lr')\n",
        "parser.add_argument('--wd', type=float, default=0.001, help='weight decay')\n",
        "parser.add_argument('--pred_step', type=int, default=12, help='step')\n",
        "args = parser.parse_args()\n",
        "print('this is arges',args)\n",
        "device = args.device"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--device DEVICE] [--run_times RUN_TIMES]\n",
            "                             [--epoch EPOCH] [--batch_size BATCH_SIZE]\n",
            "                             [--city_num CITY_NUM] [--gnn_h GNN_H]\n",
            "                             [--rnn_h RNN_H] [--rnn_l RNN_L] [--aqi_em AQI_EM]\n",
            "                             [--poi_em POI_EM] [--wea_em WEA_EM] [--lr LR]\n",
            "                             [--wd WD] [--pred_step PRED_STEP]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-cbf40351-76c0-4104-9be8-1e1693757acb.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGqMeLt3CrUJ"
      },
      "source": [
        "train_dataset = trainDataset()\n",
        "train_loader = Data.DataLoader(train_dataset,batch_size=128,shuffle=True)\n",
        "val_dataset = valDataset()\n",
        "val_loader = Data.DataLoader(val_dataset,\n",
        "                             batch_size=128,\n",
        "                             shuffle=True)\n",
        "\n",
        "test_dataset = testDataset()\n",
        "test_loader = Data.DataLoader(test_dataset,\n",
        "                              batch_size=128,\n",
        "                              shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imRPOzD4FJaJ"
      },
      "source": [
        "## model part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlzLq8jzFL8A"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
        "from torch_scatter import scatter_mean, scatter_add\n",
        "\n",
        "\n",
        "class RNNEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(RNNEncoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size,\n",
        "                            hidden_size,\n",
        "                            num_layers,\n",
        "                            batch_first=True)\n",
        "\n",
        "    def forward(self, x, h0, c0):\n",
        "        # Set initial hidden and cell states\n",
        "        # Forward propagate LSTM\n",
        "        out, (h_n, c_n) = self.lstm(x, (h0, c0))  \n",
        "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        return h_n, c_n\n",
        "\n",
        "\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(RNNDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size,\n",
        "                            hidden_size,\n",
        "                            num_layers,\n",
        "                            batch_first=True)\n",
        "        self.lin = nn.Linear(hidden_size, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, h_0, c_0):\n",
        "        # Forward propagate LSTM\n",
        "        out, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
        "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        out = self.lin(out)\n",
        "        out = self.relu(out)\n",
        "        # Decode the hidden state of the last time step\n",
        "        return out, h_n, c_n\n",
        "\n",
        "\n",
        "class GlobalModel(torch.nn.Module):\n",
        "    def __init__(self, aqi_em, rnn_h, rnn_l, gnn_h):\n",
        "        super(GlobalModel, self).__init__()\n",
        "        self.aqi_em = aqi_em\n",
        "        self.rnn_h = rnn_h\n",
        "        self.gnn_h = gnn_h\n",
        "        self.aqi_embed = Seq(Lin(1, aqi_em), ReLU())\n",
        "        self.aqi_rnn = nn.LSTM(aqi_em, rnn_h, rnn_l, batch_first=True)\n",
        "        self.city_gnn = CityGNN(rnn_h, 2, gnn_h)\n",
        "\n",
        "    def batchInput(self, x, edge_w, edge_conn):\n",
        "        sta_num = x.shape[1]\n",
        "        x = x.reshape(-1, x.shape[-1])\n",
        "        edge_w = edge_w.reshape(-1, edge_w.shape[-1])\n",
        "        for i in range(edge_conn.size(0)):\n",
        "            edge_conn[i, :] = torch.add(edge_conn[i, :], i * sta_num)\n",
        "        edge_conn = edge_conn.transpose(0, 1)\n",
        "        edge_conn = edge_conn.reshape(2, -1)\n",
        "        return x, edge_w, edge_conn\n",
        "\n",
        "    def forward(self, city_aqi, city_conn, city_w, city_num):\n",
        "        city_aqi = city_aqi.unsqueeze(dim=-1)\n",
        "        city_aqi = self.aqi_embed(city_aqi)\n",
        "        city_aqi, _ = self.aqi_rnn(city_aqi.reshape(-1, 24, self.aqi_em))\n",
        "        city_aqi = city_aqi.reshape(-1, 10, 24, self.rnn_h)\n",
        "        city_aqi = city_aqi.transpose(1, 2)\n",
        "        city_aqi = city_aqi.reshape(-1, city_num, city_aqi.shape[-1])\n",
        "\n",
        "        city_conn = city_conn.transpose(1, 2).repeat(24, 1, 1)\n",
        "        city_w = city_w.reshape(-1, city_w.shape[-2], city_w.shape[-1])\n",
        "        # print(city_aqi.shape,city_conn.shape, city_w.shape)\n",
        "        city_x, city_weight, city_conn = self.batchInput(\n",
        "            city_aqi, city_w, city_conn)\n",
        "        out = self.city_gnn(city_x, city_conn, city_weight)\n",
        "        out = out.reshape(-1, 24, city_num, out.shape[-1])\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class CityGNN(torch.nn.Module):\n",
        "    def __init__(self, node_h, edge_h, gnn_h):\n",
        "        super(CityGNN, self).__init__()\n",
        "        self.node_mlp_1 = Seq(Lin(2 * node_h + edge_h, gnn_h),\n",
        "                              ReLU(inplace=True))\n",
        "        self.node_mlp_2 = Seq(Lin(node_h + gnn_h, gnn_h), ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        # x: [N, F_x], where N is the number of nodes.\n",
        "        # edge_index: [2, E] with max entry N - 1.\n",
        "        # edge_attr: [E, F_e]\n",
        "        row, col = edge_index\n",
        "        out = torch.cat([x[row], x[col], edge_attr], dim=1)\n",
        "        out = self.node_mlp_1(out)\n",
        "        out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n",
        "        out = torch.cat([x, out], dim=1)\n",
        "        return self.node_mlp_2(out)\n",
        "\n",
        "\n",
        "class CityModel(nn.Module):\n",
        "    \"\"\"Station graph\"\"\"\n",
        "    def __init__(self, aqi_em, poi_em, wea_em, rnn_h, rnn_l, gnn_h):\n",
        "        super(CityModel, self).__init__()\n",
        "        self.rnn_h = rnn_h\n",
        "        self.gnn_h = gnn_h\n",
        "        self.rnn_l = rnn_l\n",
        "        self.aqi_embed = Seq(Lin(1, aqi_em), ReLU())\n",
        "        self.poi_embed = Seq(Lin(5, poi_em), ReLU())\n",
        "        self.city_embed = Seq(Lin(gnn_h, wea_em), ReLU())\n",
        "        self.wea_embed = Seq(Lin(5, wea_em), ReLU())\n",
        "        self.sta_gnn = StaGNN(aqi_em + poi_em, 2, gnn_h, 2 * wea_em)\n",
        "        self.encoder = RNNEncoder(input_size=gnn_h,\n",
        "                                  hidden_size=rnn_h,\n",
        "                                  num_layers=rnn_l)\n",
        "        self.decoder_embed = Seq(Lin(1, aqi_em), ReLU())\n",
        "        self.decoder = RNNDecoder(input_size=4 + aqi_em,\n",
        "                                  hidden_size=rnn_h,\n",
        "                                  num_layers=rnn_l)\n",
        "\n",
        "    def batchInput(self, x, edge_w, edge_conn):\n",
        "        sta_num = x.shape[1]\n",
        "        x = x.reshape(-1, x.shape[-1])\n",
        "        edge_w = edge_w.reshape(-1, edge_w.shape[-1])\n",
        "        for i in range(edge_conn.size(0)):\n",
        "            edge_conn[i, :] = torch.add(edge_conn[i, :], i * sta_num)\n",
        "        edge_conn = edge_conn.transpose(0, 1)\n",
        "        edge_conn = edge_conn.reshape(2, -1)\n",
        "        return x, edge_w, edge_conn\n",
        "\n",
        "    def forward(self, city_data, city_u, device):\n",
        "        sta_aqi, sta_conn, sta_poi, sta_w, sta_wea, sta_for, _ = city_data\n",
        "        sta_num = sta_aqi.shape[1]\n",
        "        sta_x = sta_aqi.unsqueeze(dim=-1)\n",
        "        sta_x = self.aqi_embed(sta_x)\n",
        "        sta_poi = self.poi_embed(sta_poi)\n",
        "        sta_poi = sta_poi.unsqueeze(dim=-2).repeat_interleave(24, dim=-2)\n",
        "        sta_x = torch.cat([sta_x, sta_poi], dim=-1)\n",
        "        sta_x = sta_x.transpose(1, 2)\n",
        "        sta_x = sta_x.reshape(-1, sta_x.shape[-2], sta_x.shape[-1])\n",
        "\n",
        "        sta_conn = sta_conn.transpose(1, 2).repeat(24, 1, 1)\n",
        "        sta_w = sta_w.reshape(-1, sta_w.shape[-2], sta_w.shape[-1])\n",
        "        # print(sta_x.shape,sta_conn.shape,sta_w.shape)\n",
        "        sta_x, sta_weight, sta_conn = self.batchInput(sta_x, sta_w, sta_conn)\n",
        "        city_u = self.city_embed(city_u)\n",
        "        sta_wea = self.wea_embed(sta_wea)\n",
        "        sta_u = torch.cat([city_u, sta_wea], dim=-1)\n",
        "        sta_x = self.sta_gnn(sta_x, sta_conn, sta_weight, sta_u, sta_num)\n",
        "        sta_x = sta_x.reshape(-1, 24, sta_num, sta_x.shape[-1]).transpose(1, 2)\n",
        "        sta_x = sta_x.reshape(-1, 24, sta_x.shape[-1])\n",
        "\n",
        "        h0 = torch.randn(self.rnn_l, sta_x.size(0), self.rnn_h).to(device)\n",
        "        c0 = torch.randn(self.rnn_l, sta_x.size(0), self.rnn_h).to(device)\n",
        "        h_x, c_x = self.encoder(sta_x, h0, c0)\n",
        "\n",
        "        outputs = torch.zeros((sta_x.size(0), sta_for.size(1), 1)).to(device)\n",
        "        aqi = sta_aqi[:, :, -1].reshape(-1, 1)\n",
        "        sta_for = sta_for.repeat(sta_num, 1, 1)\n",
        "        for i in range(sta_for.size(1)):\n",
        "            aqi_em = self.decoder_embed(aqi)\n",
        "            inputs = torch.cat((aqi_em, sta_for[:, i]), dim=-1)\n",
        "            inputs = inputs.unsqueeze(dim=1)\n",
        "            output, h_x, c_x = self.decoder(inputs, h_x, c_x)\n",
        "            output = output.reshape(-1, 1)\n",
        "            outputs[:, i] = output\n",
        "            aqi = output\n",
        "        outputs = outputs.reshape(-1, sta_num, sta_for.size(1))\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class StaGNN(torch.nn.Module):\n",
        "    def __init__(self, node_h, edge_h, gnn_h, u_h):\n",
        "        super(StaGNN, self).__init__()\n",
        "        self.node_mlp_1 = Seq(Lin(2 * node_h + edge_h, gnn_h),\n",
        "                              ReLU(inplace=True))\n",
        "        self.node_mlp_2 = Seq(Lin(node_h + gnn_h + u_h, gnn_h),\n",
        "                              ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, u, sta_num):\n",
        "        # x: [N, F_x], where N is the number of nodes.\n",
        "        # edge_index: [2, E] with max entry N - 1.\n",
        "        # edge_attr: [E, F_e]\n",
        "        u = u.reshape(-1, u.shape[-1])\n",
        "        u = u.repeat(sta_num, 1)\n",
        "        row, col = edge_index\n",
        "        out = torch.cat([x[row], x[col], edge_attr], dim=1)\n",
        "        out = self.node_mlp_1(out)\n",
        "        out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n",
        "        out = torch.cat([x, out, u], dim=1)\n",
        "        return self.node_mlp_2(out)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waYmpqK1FihQ"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d55Wn5MqF2Pj"
      },
      "source": [
        "parser = argparse.ArgumentParser(description='Multi-city AQI forecasting')\n",
        "parser.add_argument('--device', type=str, default='cuda', help='')\n",
        "parser.add_argument('--run_times', type=int, default=5, help='')\n",
        "parser.add_argument('--epoch', type=int, default=300, help='')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='')\n",
        "parser.add_argument('--city_num', type=int, default=10, help='')\n",
        "parser.add_argument('--gnn_h', type=int, default=32, help='')\n",
        "parser.add_argument('--rnn_h', type=int, default=64, help='')\n",
        "parser.add_argument('--rnn_l', type=int, default=1, help='')\n",
        "parser.add_argument('--aqi_em', type=int, default=16, help='')\n",
        "parser.add_argument('--poi_em', type=int, default=8, help='poi embedding')\n",
        "parser.add_argument('--wea_em', type=int, default=12, help='wea embedding')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='lr')\n",
        "parser.add_argument('--wd', type=float, default=0.001, help='weight decay')\n",
        "parser.add_argument('--pred_step', type=int, default=12, help='step')\n",
        "args = parser.parse_args()\n",
        "print('this is arges',args)\n",
        "device = args.device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0VMLV9dFmY2",
        "outputId": "83ab79fa-b1b9-445e-b21f-f48f0fb29a56"
      },
      "source": [
        "#global_model = GlobalModel(args.aqi_em, args.rnn_h, args.rnn_l,\n",
        "#                            args.gnn_h).to(device)\n",
        "##jiaxing_model = CityModel(args.aqi_em, args.poi_em, args.wea_em,\n",
        "#                          args.rnn_h, args.rnn_l, args.gnn_h).to(device)\n",
        "#shanghai_model = CityModel(args.aqi_em, args.poi_em, args.wea_em,\n",
        "#                            args.rnn_h, args.rnn_l, args.gnn_h).to(device)\n",
        "#suzhou_model = CityModel(args.aqi_em, args.poi_em, args.wea_em, args.rnn_h,\n",
        "#                          args.rnn_l, args.gnn_h).to(device)\n",
        "\n",
        "global_model = GlobalModel(16, 64, 1,\n",
        "                            32).to(device)\n",
        "jiaxing_model = CityModel(16, 8, 12,\n",
        "                          64, 1, 32).to(device)\n",
        "shanghai_model = CityModel(16, 8, 12,\n",
        "                          64, 1, 32).to(device)\n",
        "suzhou_model = CityModel(16, 8, 12,\n",
        "                          64, 1, 32).to(device)\n",
        "\n",
        "city_model_num = sum(p.numel() for p in global_model.parameters()\n",
        "                      if p.requires_grad)\n",
        "print('city_model:', 'Trainable,', city_model_num)\n",
        "\n",
        "shanghai_model_num = sum(p.numel() for p in shanghai_model.parameters()\n",
        "                          if p.requires_grad)\n",
        "print('shanghai_model_num:', 'Trainable,', shanghai_model_num)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "params = list(global_model.parameters()) + list(jiaxing_model.parameters()) + \\\n",
        "    list(shanghai_model.parameters()) + list(suzhou_model.parameters())\n",
        "optimizer = torch.optim.Adam(params, lr=0.001, weight_decay=0.001)\n",
        "\n",
        "val_loss_min = np.inf"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "city_model: Trainable, 28320\n",
            "shanghai_model_num: Trainable, 51973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKlUo-FpG_Yj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}